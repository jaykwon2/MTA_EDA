{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "596f5b9d",
   "metadata": {},
   "source": [
    "## Question:  \n",
    "I decided to target the following 27 week time period to perform my EDA on: 2020-07-25 to 2021-01-29. I was interested in this time period because I wanted to find insights on how the MTA traffic pattern changes as we move out of summer (August) and into the new school year (September), onto the holiday season in December, and into the new year. One would expect the traffic to increase in September. The government fiscal year started on October 1st. Public holidays celebrated in NY include:  \n",
    "  \n",
    "Labor Day \tMon, Sep 7, 2020  \n",
    "Columbus Day \tMon, Oct 12, 2020  \n",
    "Veterans Day \tWed, Nov 11, 2020  \n",
    "Thanksgiving \tThu, Nov 26, 2020  \n",
    "Christmas Day \tFri, Dec 25, 2020  \n",
    "New Year's Day \tFri, Jan 1, 2021  \n",
    "Martin Luther King Jr. Day \tMon, Jan 18, 2021  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ba4f0e",
   "metadata": {},
   "source": [
    "## Importing MTA data from website into a .db file for SQL queries\n",
    "\n",
    "I used the 'get_mta.py' file provided and imported data from the mta website ('http://web.mta.info/developers/turnstile.html') following the the instructions on the 'get_mta.md' readme file.  \n",
    "  \n",
    "The resulting .db file was saved in the 'data' folder as 'mta_data - 27 weeks - 2020.08.01 to 2021.01.30.db'\n",
    "  \n",
    "The following command was used to get the data for the months of August, 2020 to January, 2021:  \n",
    "  \n",
    "python 'get_mta.py' \"(2008|2009|2010|2011|2012|2101)\"\n",
    "\n",
    "27 weeks to collect:\n",
    "\n",
    "['2021-01-30', '2021-01-23', '2021-01-16', '2021-01-09', '2021-01-02', '2020-12-26', '2020-12-19', '2020-12-12', '2020-12-05', '2020-11-28', '2020-11-21', \n",
    "'2020-11-14', '2020-11-07', '2020-10-31', '2020-10-24', '2020-10-17', '2020-10-10', '2020-10-03', '2020-09-26', '2020-09-19', '2020-09-12', '2020-09-05', '2020-08-29', '2020-08-22', '2020-08-15', '2020-08-08', '2020-08-01']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dcd377",
   "metadata": {},
   "source": [
    "## Using SQLAlchemy to import SQL query as a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "246f71f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if SQLAlchemy is not installed:\n",
    "\n",
    "#!conda install -c anaconda sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e85a517b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "804229d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Engine(sqlite:///mta_data.db)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine = create_engine(\"sqlite:///mta_data.db\") #telling it to use sqlite specifically\n",
    "\n",
    "engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b747742d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Engine.table_names of Engine(sqlite:///mta_data.db)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tables = engine.table_names # attribute with list the table names in the database\n",
    "all_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "846614ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-4c13db206af4>:1: SADeprecationWarning: The Engine.table_names() method is deprecated and will be removed in a future release.  Please refer to Inspector.get_table_names(). (deprecated since: 1.4)\n",
      "  engine.table_names() # ??? there seems to be no name for the table.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['mta_data']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.table_names() # ??? there seems to be no name for the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c379b084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C/A</th>\n",
       "      <th>UNIT</th>\n",
       "      <th>SCP</th>\n",
       "      <th>STATION</th>\n",
       "      <th>LINENAME</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TIME</th>\n",
       "      <th>DESC</th>\n",
       "      <th>ENTRIES</th>\n",
       "      <th>EXITS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>01/23/2021</td>\n",
       "      <td>03:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>7521371</td>\n",
       "      <td>2563177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>01/23/2021</td>\n",
       "      <td>07:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>7521374</td>\n",
       "      <td>2563190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>01/23/2021</td>\n",
       "      <td>11:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>7521399</td>\n",
       "      <td>2563231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>01/23/2021</td>\n",
       "      <td>15:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>7521490</td>\n",
       "      <td>2563274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>01/23/2021</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>7521630</td>\n",
       "      <td>2563312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    C/A  UNIT       SCP STATION LINENAME DIVISION        DATE      TIME  \\\n",
       "0  A002  R051  02-00-00   59 ST  NQR456W      BMT  01/23/2021  03:00:00   \n",
       "1  A002  R051  02-00-00   59 ST  NQR456W      BMT  01/23/2021  07:00:00   \n",
       "2  A002  R051  02-00-00   59 ST  NQR456W      BMT  01/23/2021  11:00:00   \n",
       "3  A002  R051  02-00-00   59 ST  NQR456W      BMT  01/23/2021  15:00:00   \n",
       "4  A002  R051  02-00-00   59 ST  NQR456W      BMT  01/23/2021  19:00:00   \n",
       "\n",
       "      DESC  ENTRIES    EXITS  \n",
       "0  REGULAR  7521371  2563177  \n",
       "1  REGULAR  7521374  2563190  \n",
       "2  REGULAR  7521399  2563231  \n",
       "3  REGULAR  7521490  2563274  \n",
       "4  REGULAR  7521630  2563312  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_sql('SELECT * FROM mta_data', engine)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb204be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C/A</th>\n",
       "      <th>UNIT</th>\n",
       "      <th>SCP</th>\n",
       "      <th>STATION</th>\n",
       "      <th>LINENAME</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TIME</th>\n",
       "      <th>DESC</th>\n",
       "      <th>ENTRIES</th>\n",
       "      <th>EXITS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>01/23/2021</td>\n",
       "      <td>03:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>7521371</td>\n",
       "      <td>2563177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>01/23/2021</td>\n",
       "      <td>07:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>7521374</td>\n",
       "      <td>2563190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>01/23/2021</td>\n",
       "      <td>11:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>7521399</td>\n",
       "      <td>2563231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>01/23/2021</td>\n",
       "      <td>15:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>7521490</td>\n",
       "      <td>2563274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>01/23/2021</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>7521630</td>\n",
       "      <td>2563312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5673225</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>R</td>\n",
       "      <td>RIT</td>\n",
       "      <td>07/31/2020</td>\n",
       "      <td>12:59:32</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>5554</td>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5673226</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>R</td>\n",
       "      <td>RIT</td>\n",
       "      <td>07/31/2020</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>5554</td>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5673227</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>R</td>\n",
       "      <td>RIT</td>\n",
       "      <td>07/31/2020</td>\n",
       "      <td>13:11:06</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>5554</td>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5673228</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>R</td>\n",
       "      <td>RIT</td>\n",
       "      <td>07/31/2020</td>\n",
       "      <td>17:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>5554</td>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5673229</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>R</td>\n",
       "      <td>RIT</td>\n",
       "      <td>07/31/2020</td>\n",
       "      <td>21:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>5554</td>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5673230 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           C/A  UNIT       SCP        STATION LINENAME DIVISION        DATE  \\\n",
       "0         A002  R051  02-00-00          59 ST  NQR456W      BMT  01/23/2021   \n",
       "1         A002  R051  02-00-00          59 ST  NQR456W      BMT  01/23/2021   \n",
       "2         A002  R051  02-00-00          59 ST  NQR456W      BMT  01/23/2021   \n",
       "3         A002  R051  02-00-00          59 ST  NQR456W      BMT  01/23/2021   \n",
       "4         A002  R051  02-00-00          59 ST  NQR456W      BMT  01/23/2021   \n",
       "...        ...   ...       ...            ...      ...      ...         ...   \n",
       "5673225  TRAM2  R469  00-05-01  RIT-ROOSEVELT        R      RIT  07/31/2020   \n",
       "5673226  TRAM2  R469  00-05-01  RIT-ROOSEVELT        R      RIT  07/31/2020   \n",
       "5673227  TRAM2  R469  00-05-01  RIT-ROOSEVELT        R      RIT  07/31/2020   \n",
       "5673228  TRAM2  R469  00-05-01  RIT-ROOSEVELT        R      RIT  07/31/2020   \n",
       "5673229  TRAM2  R469  00-05-01  RIT-ROOSEVELT        R      RIT  07/31/2020   \n",
       "\n",
       "             TIME     DESC  ENTRIES    EXITS  \n",
       "0        03:00:00  REGULAR  7521371  2563177  \n",
       "1        07:00:00  REGULAR  7521374  2563190  \n",
       "2        11:00:00  REGULAR  7521399  2563231  \n",
       "3        15:00:00  REGULAR  7521490  2563274  \n",
       "4        19:00:00  REGULAR  7521630  2563312  \n",
       "...           ...      ...      ...      ...  \n",
       "5673225  12:59:32  REGULAR     5554      538  \n",
       "5673226  13:00:00  REGULAR     5554      538  \n",
       "5673227  13:11:06  REGULAR     5554      538  \n",
       "5673228  17:00:00  REGULAR     5554      538  \n",
       "5673229  21:00:00  REGULAR     5554      538  \n",
       "\n",
       "[5673230 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64e06876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5673230, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6f6ad1",
   "metadata": {},
   "source": [
    "## Field Descriptions from MTA website  \n",
    "http://web.mta.info/developers/resources/nyct/turnstile/ts_Field_Description.txt  \n",
    "\n",
    "Field Description\n",
    "\n",
    "C/A,UNIT,SCP,STATION,LINENAME,DIVISION,DATE,TIME,DESC,ENTRIES,EXITS\n",
    "\n",
    "\n",
    "C/A      = Control Area (A002)\n",
    "UNIT     = Remote Unit for a station (R051)\n",
    "SCP      = Subunit Channel Position represents an specific address for a device (02-00-00)\n",
    "STATION  = Represents the station name the device is located at\n",
    "LINENAME = Represents all train lines that can be boarded at this station\n",
    "           Normally lines are represented by one character.  LINENAME 456NQR repersents train server for 4, 5, 6, N, Q, and R trains.\n",
    "DIVISION = Represents the Line originally the station belonged to BMT, IRT, or IND   \n",
    "DATE     = Represents the date (MM-DD-YY)\n",
    "TIME     = Represents the time (hh:mm:ss) for a scheduled audit event\n",
    "DESc     = Represent the \"REGULAR\" scheduled audit event (Normally occurs every 4 hours)\n",
    "           1. Audits may occur more that 4 hours due to planning, or troubleshooting activities. \n",
    "           2. Additionally, there may be a \"RECOVR AUD\" entry: This refers to a missed audit that was recovered. \n",
    "ENTRIES  = The comulative entry register value for a device\n",
    "EXIST    = The cumulative exit register value for a device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04345c53",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86d0cdbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['C/A', 'UNIT', 'SCP', 'STATION', 'LINENAME', 'DIVISION', 'DATE', 'TIME',\n",
       "       'DESC', 'ENTRIES', 'EXITS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns # unlike in the MTA 1 exercise, it seems the 'EXITS' column doesn't have a bunch of spaces at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0f1159a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['C/A', 'UNIT', 'SCP', 'STATION', 'LINENAME', 'DIVISION', 'DATE', 'TIME',\n",
       "       'DESC', 'ENTRIES', 'EXITS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# but will still strip white spaces for good measure\n",
    "df.columns = [column.strip() for column in df.columns] # reassign column names for \n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2949d458",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5673230 entries, 0 to 5673229\n",
      "Data columns (total 11 columns):\n",
      " #   Column    Dtype \n",
      "---  ------    ----- \n",
      " 0   C/A       object\n",
      " 1   UNIT      object\n",
      " 2   SCP       object\n",
      " 3   STATION   object\n",
      " 4   LINENAME  object\n",
      " 5   DIVISION  object\n",
      " 6   DATE      object\n",
      " 7   TIME      object\n",
      " 8   DESC      object\n",
      " 9   ENTRIES   int64 \n",
      " 10  EXITS     int64 \n",
      "dtypes: int64(2), object(9)\n",
      "memory usage: 476.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ad6138",
   "metadata": {},
   "source": [
    "'DATE' and 'TIME' columnes are of type \"object\" which often means string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2de30275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'03:00:00'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's take a look at the specific entry for row 0\n",
    "df.iloc[0]['DATE'] # the quotes around the output implies that 'DATE' column is of type string\n",
    "df.iloc[0]['TIME'] # same with 'TIME' column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f7b8fd",
   "metadata": {},
   "source": [
    "### converting 'DATE' and 'TIME' columns into a DateTime object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67194fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          01/23/2021 03:00:00\n",
       "1          01/23/2021 07:00:00\n",
       "2          01/23/2021 11:00:00\n",
       "3          01/23/2021 15:00:00\n",
       "4          01/23/2021 19:00:00\n",
       "                  ...         \n",
       "5673225    07/31/2020 12:59:32\n",
       "5673226    07/31/2020 13:00:00\n",
       "5673227    07/31/2020 13:11:06\n",
       "5673228    07/31/2020 17:00:00\n",
       "5673229    07/31/2020 21:00:00\n",
       "Name: DATE_TIME, Length: 5673230, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['DATE_TIME'] = df['DATE'] + ' ' + df['TIME'] # concatenate with a space seperator; Pandas can parse this format when converting to datetime\n",
    "df['DATE_TIME'] # still a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c99b9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DATE_TIME'] = pd.to_datetime(df['DATE_TIME']) # converts our new 'DATE_TIME' column into a datetime object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce84fb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() # dtype for 'DATE_TIME' column is now datetime64[ns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e66ea09",
   "metadata": {},
   "source": [
    "### Check for Duplicate Entries\n",
    "Each unique turnstile is represented by the same values for the following columns:  \n",
    "'C/A'  \n",
    "'UNIT'   \n",
    "'SCP'   \n",
    "'STATION'  \n",
    "- Each combination of `C/A`, `UNIT`, `SCP`, and `STATION` represents a unique turnstile.\n",
    "- For each turnstile, for a given day, there should be exactly 6 rows (1 for each time slot, i.e. datetime)\n",
    "- For each turnstile, the `DATE_TIME` entries should not be duplicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1effd3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code modified from MTA 1 exercise\n",
    "# verify that \"C/A\", \"UNIT\", \"SCP\", \"STATION\", \"DATE_TIME\" is unique\n",
    "(df\n",
    " .groupby([\"C/A\", \"UNIT\", \"SCP\", \"STATION\", \"DATE_TIME\"])\n",
    " .ENTRIES.count()\n",
    " .reset_index()\n",
    " .sort_values(\"ENTRIES\", ascending=False)).head(65) # looks like there are 61 duplicate entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9380ecad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get back to this if time permits; we should be \n",
    "# (df\n",
    "#  .groupby([\"C/A\", \"UNIT\", \"SCP\", \"STATION\", \"DATE_TIME\"])\n",
    "#  .ENTRIES.count() > 1).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111ceb36",
   "metadata": {},
   "source": [
    "It seems when there are duplicate entries, the later row has a higher, presumably more accurate count for 'ENTRIES' or 'EXITS', hence let's just keep the later row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd55bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa762ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values([\"C/A\", \"UNIT\", \"SCP\", \"STATION\", \"DATE_TIME\"], \n",
    "                          inplace=True, ascending=False)\n",
    "df2 = df.drop_duplicates(subset=[\"C/A\", \"UNIT\", \"SCP\", \"STATION\", \"DATE_TIME\"], inplace=False, keep='last').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a07c2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f37799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# did it drop the correct number of rows? yes\n",
    "df.shape[0]-df2.shape[0] # 5673230 - 5673169 = 61 duplicates we observed above have been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93f7ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df2\n",
    " .groupby([\"C/A\", \"UNIT\", \"SCP\", \"STATION\", \"DATE_TIME\"])\n",
    " .ENTRIES.count()\n",
    " .reset_index()\n",
    " .sort_values(\"ENTRIES\", ascending=False)).head(5) # no more duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4dd0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3de6549",
   "metadata": {},
   "source": [
    "LINENAME = Represents all train lines that can be boarded at this station\n",
    "           Normally lines are represented by one character.  LINENAME 456NQR repersents train server for 4, 5, 6, N, Q, and R trains.\n",
    "DIVISION = Represents the Line originally the station belonged to BMT, IRT, or IND   \n",
    "DATE     = Represents the date (MM-DD-YY)\n",
    "TIME     = Represents the time (hh:mm:ss) for a scheduled audit event\n",
    "DESc     = Represent the \"REGULAR\" scheduled audit event (Normally occurs every 4 hours)\n",
    "           1. Audits may occur more that 4 hours due to planning, or troubleshooting activities. \n",
    "           2. Additionally, there may be a \"RECOVR AUD\" entry: This refers to a missed audit that was recovered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb334b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop DATE and TIME columns since we have DATE_TIME\n",
    "# let's keep DIVISION and DESC for now.\n",
    "df2.drop([\"DATE\", \"TIME\"], axis=1, errors=\"ignore\") # ignore errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b976fdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# end of day entries and exits occur at 8pm 20:00(so really should be looking at the first entry of the next day (00:00), then sift the Dates over, but we'll say it's 8pm for now; but come back and fix if time permits\n",
    "\n",
    "# There 6 entries for each turnstile+date; let's get a dataframe with only the last timestamp (8pm) of the day; dropping the first 5 entries for the day; this will represent a daily time series; not a 4-hour time series\n",
    "\n",
    "df2_daily_cum = (df2\n",
    "                        .groupby([\"C/A\", \"UNIT\", \"SCP\", \"STATION\", \"DATE\"],as_index=False)\n",
    "                        [['LINENAME','DESC','DIVISION','ENTRIES','EXITS']].first()).copy()\n",
    "# because of the groupby, the time parameter of DATE_TIME is reduced to a string column called 'DATE'\n",
    "# convert 'DATE' to timeseries data\n",
    "df['DATE_TIME'] = pd.to_datetime(df['DATE_TIME']) \n",
    "df2_daily_cum['DATE'] = pd.to_datetime(df2_daily_cum['DATE'])\n",
    "df2_daily_cum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb881f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_daily_cum.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2137f062",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_daily_cum = df2_daily_cum.sort_values(by=['C/A','UNIT','SCP','STATION','DATE'], inplace=False)\n",
    "df2_daily_cum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98da52dc",
   "metadata": {},
   "source": [
    "- as of now we only have the cummulative counter values for entries and exits\n",
    "- let's get the daily counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8afe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find daily ENTRIES and EXITS ; right now these are cumulative values on the counters\n",
    "# exits - previous exits = daily exit count ; likewise for entries\n",
    "\n",
    "df2_daily_cum[[\"PREV_DATE\", \"PREV_ENTRIES\", \"PREV_EXITS\"]] = (df2_daily_cum\n",
    "                                                       .groupby([\"C/A\", \"UNIT\", \"SCP\", \"STATION\"])[\"DATE\", \"ENTRIES\", 'EXITS']\n",
    "                                                       .apply(lambda grp: grp.shift(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bc2c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_daily_cum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93214f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows for the earliest date in the df\n",
    "df2_daily_cum.dropna(subset=[\"PREV_DATE\"], axis=0, inplace=True)\n",
    "df2_daily_cum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea55ea74",
   "metadata": {},
   "outputs": [],
   "source": [
    "937597 - 932541 # The 1st date for each turnstile should have been dropped, therefore, there should be 5056 turnstiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca9deb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make like easier, let's make a list of the columns that identifies a unique turnstile, we seem to be using it a lot.\n",
    "turnstile_col_list = ['C/A','UNIT','SCP','STATION']\n",
    "\n",
    "# how many unique turnstiles are there?\n",
    "(df\n",
    " .groupby(turnstile_col_list)\n",
    " .count()) # note, we used df here: output: 5056 <-- correct\n",
    "(df2_daily_cum\n",
    " .groupby(turnstile_col_list)\n",
    " .count()) # note, we used df here: output: 5029 <-- ??? why is it less?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856f7723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many stations are there?\n",
    "(df\n",
    " .groupby('STATION').count()) # for df, output: 379\n",
    "(df2_daily_cum\n",
    " .groupby('STATION').count()) # for df2_daily_cum, output:379\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1647d969",
   "metadata": {},
   "source": [
    "### list of things to check when time permits  \n",
    "- are the station names unique?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00aefe31",
   "metadata": {},
   "source": [
    "## fixing reverse entries  \n",
    "- for a given day, for a given turnstile, PREV_ENTRIES should always be less than ENTRIES (entries for that day); if not, there was some error in entering the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea57be77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by turnstile and see how rows/days have an error where the previous entries is greater than the current day's entries\n",
    "(df2_daily_cum[df2_daily_cum[\"ENTRIES\"] < df2_daily_cum[\"PREV_ENTRIES\"]]\n",
    "    .groupby([\"C/A\", \"UNIT\", \"SCP\", \"STATION\"])\n",
    "    .size().sort_values(ascending=False).head(50))\n",
    "#377 turnstiles have at least one of these errors. A lot of them seem to have 188 errors, why is 188 errors common???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d34a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df2_daily_cum[df2_daily_cum[\"ENTRIES\"] < df2_daily_cum[\"PREV_ENTRIES\"]]\n",
    "    .groupby([\"C/A\", \"UNIT\", \"SCP\", \"STATION\"])\n",
    "    .size().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e5d2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_sum = (df2_daily_cum[df2_daily_cum[\"ENTRIES\"] < df2_daily_cum[\"PREV_ENTRIES\"]]\n",
    "    .groupby([\"C/A\", \"UNIT\", \"SCP\", \"STATION\"])\n",
    "    .size().sum().copy())\n",
    "reverse_sum / df2_daily_cum.shape[0]\n",
    "# 0.90% of the rows have this reverse error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdde26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fix this error: (code modified from MTA 3 exercise)\n",
    "# def get_daily_counts(row, max_counter):\n",
    "#     counter = row[\"ENTRIES\"] - row[\"PREV_ENTRIES\"]\n",
    "#     if counter < 0:\n",
    "#         counter = -counter\n",
    "#     if counter > max_counter:\n",
    "#         print(row[\"ENTRIES\"], row[\"PREV_ENTRIES\"])\n",
    "#         return 0\n",
    "#     return counter\n",
    "\n",
    "# # If counter is > 1Million, then the counter might have been reset.  \n",
    "# # Just set it to zero as different counters have different cycle limits\n",
    "# _ = df2_daily_cum.apply(get_daily_counts, axis=1, max_counter=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18b6c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix this error: (code modified from MTA 3 exercise)\n",
    "def get_daily_counts(row, max_counter):\n",
    "    counter = row[\"ENTRIES\"] - row[\"PREV_ENTRIES\"]\n",
    "    if counter < 0:\n",
    "        # Maybe counter is reversed?\n",
    "        counter = -counter\n",
    "    if counter > max_counter:\n",
    "        # Maybe counter was reset to 0? \n",
    "        print(row[\"ENTRIES\"], row[\"PREV_ENTRIES\"])\n",
    "        counter = min(row[\"ENTRIES\"], row[\"PREV_ENTRIES\"])\n",
    "    if counter > max_counter:\n",
    "        # Check it again to make sure we're not still giving a counter that's too big\n",
    "        return 0\n",
    "    return counter\n",
    "\n",
    "# !! we're implying that there's no way a million people passes by a turnstile in a given day. If this happens, then something went wrong and it's probably more prudent to add a value of 0 to discount that day's daily count.\n",
    "# This function does not correct the problem of the cummulative counts being reversed, but it makes sure that the daily count (non cummulative) is correct by reversing the minus sign.\n",
    "\n",
    "# If counter is > 1Million, then the counter might have been reset.  \n",
    "# Just set it to zero as different counters have different cycle limits\n",
    "# It'd probably be a good idea to use a number even significantly smaller than 1 million as the limit!\n",
    "\n",
    "# create new column \"DAILY_ENTRIES\" of the daily count of turnstiles for entries, using the custom function above.\n",
    "df2_daily_cum[\"DAILY_ENTRIES\"] = df2_daily_cum.apply(get_daily_counts, axis=1, max_counter=200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db625b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df2_daily_cum[df2_daily_cum[\"ENTRIES\"] < df2_daily_cum[\"PREV_ENTRIES\"]]\n",
    "    .groupby([\"C/A\", \"UNIT\", \"SCP\", \"STATION\"])\n",
    "    .size())\n",
    "\n",
    "# notice the number of reversed entries does not change, when the daily counts of these rows are calculated, the result has the correct absolute value but has a minus sign, we make sure that this sign is reversed to be positive. So the daily counts are correct even though the prev_entries and entries columns are reversed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1198c6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_daily_cum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e30da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we created daily entries, now do the same for exits.\n",
    "def get_daily_exits(row, max_counter):\n",
    "    counter = row[\"EXITS\"] - row[\"PREV_EXITS\"]\n",
    "    if counter < 0:\n",
    "        # Maybe counter is reversed?\n",
    "        counter = -counter\n",
    "    if counter > max_counter:\n",
    "        # Maybe counter was reset to 0? \n",
    "        print(row[\"EXITS\"], row[\"PREV_EXITS\"])\n",
    "        counter = min(row[\"EXITS\"], row[\"PREV_EXITS\"])\n",
    "    if counter > max_counter:\n",
    "        # Check it again to make sure we're not still giving a counter that's too big\n",
    "        return 0\n",
    "    return counter\n",
    "\n",
    "# If counter is > 1Million, then the counter might have been reset.  \n",
    "# Just set it to zero as different counters have different cycle limits\n",
    "# It'd probably be a good idea to use a number even significantly smaller than 1 million as the limit!\n",
    "\n",
    "df2_daily_cum[\"DAILY_EXITS\"] = df2_daily_cum.apply(get_daily_exits, axis=1, max_counter=200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aed264",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2_daily_cum # now we see that we have the daily entries and daily exit counts for each turnstile (last to columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffd3138",
   "metadata": {},
   "source": [
    "## daily Station exits and entries (combine turnstiles within station)\n",
    "\n",
    "- recall, a unique turnstile is defined by ['C/A','UNIT','SCP','STATION']\n",
    "- it's the SCP column that specifies a unique turnstile within a station.\n",
    "- to specify a unique station, group only by ['C/A','UNIT','STATION'], i.e. leave out the sation\n",
    "- from MTA 3: \"There are some ControlArea/Unit/Station groups that have a single\n",
    "  turnstile, but most have multiple turnstiles -- same value for the\n",
    "  C/A, UNIT and STATION columns, different values for the SCP column.\"\n",
    "  \n",
    "*** IMPORTANT NOTE ON ['C/A','UNIT','STATION'] vs ['STATION']:  \n",
    "    --> ['STATION'] is the station name and is unique (supposedly, but somewhat skeptical). But some stations have many lines running through them. ['C/A','UNIT','STATION'] may refer to different areas of the station where you can access different lines. But ['STATION'] refers to that physical location station for all the entrances/exits/lines/turnstile.  \n",
    "    --> I will just be using ['STATION'] for my project ie. station_daily DataFrame. Will create ca_unit_station_daily DataFrame as well but not sure if I'll use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1411ef1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_unit_station_daily = df2_daily_cum.groupby([\"C/A\", \"UNIT\", \"STATION\", \"DATE\"])[['DAILY_ENTRIES','DAILY_EXITS']].sum().reset_index().copy()\n",
    "\n",
    "ca_unit_station_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7772898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# are the station names unique? we should get the same dimensions if we group just by station and date\n",
    "station_daily_test = df2_daily_cum.groupby([\"STATION\", \"DATE\"])[['DAILY_ENTRIES','DAILY_EXITS']].sum().reset_index()\n",
    "station_daily_test\n",
    "# ???? we get about half the number of rows, which implies a ton of names being reused; maybe ['C/A','UNIT','STATION'] specifies a part of the station? (see explation in md cell above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d3dc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily Entries and Exits for entire station\n",
    "station_daily = df2_daily_cum.groupby([\"STATION\", \"DATE\"])[['DAILY_ENTRIES','DAILY_EXITS']].sum().reset_index().copy()\n",
    "\n",
    "station_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7bb2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total entries and exits for the entire 27 week period\n",
    "# sorted by entries, descending\n",
    "station_total_entries = station_daily.groupby('STATION').sum()\\\n",
    "    .sort_values('DAILY_ENTRIES', ascending=False)\\\n",
    "    .reset_index().copy()\n",
    "station_total_entries.rename(columns={'DAILY_ENTRIES': 'TOTAL_ENTRIES', 'DAILY_EXITS': 'TOTAL_EXITS'}, inplace=True)\n",
    "station_total_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a0ac0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorted by exits (descending)\n",
    "station_total_exits = station_daily.groupby('STATION').sum()\\\n",
    "    .sort_values('DAILY_EXITS', ascending=False)\\\n",
    "    .reset_index().copy()\n",
    "\n",
    "station_total_exits.rename(columns={'DAILY_ENTRIES': 'TOTAL_ENTRIES', 'DAILY_EXITS': 'TOTAL_EXITS'}, inplace=True)\n",
    "                           \n",
    "station_total_exits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec97735",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_total_exits.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121923bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = station_total_exits['TOTAL_ENTRIES'].sum() - station_total_exits['TOTAL_EXITS'].sum()\n",
    "diff2 = station_total_entries['TOTAL_ENTRIES'].sum() - station_total_entries['TOTAL_EXITS'].sum()\n",
    "diff == diff2\n",
    "\n",
    "print(diff) # ~12M people gone missing. Where did they go?\n",
    "diff / station_total_exits['TOTAL_ENTRIES'].sum() # 3.7% of the people that entered the subway disappeared\n",
    "\n",
    "# but with counter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a0a373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the top 10 exit stations not the same as top 10 entries\n",
    "# BUT 34 ST-PENN STA is the most popular stations for exits AND entries\n",
    "\n",
    "station_total_entries['STATION'].head(10) == station_total_exits['STATION'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7f228e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.bar(x=station_total_entries['STATION'][:10], height=station_total_entries['TOTAL_ENTRIES'][:10], width = 0.4, label=\"Daily Entries\") # ranked by Entries and showing entries\n",
    "\n",
    "plt.bar(x=station_total_exits['STATION'][:10],\n",
    "        height=station_total_exits['TOTAL_EXITS'][:10], width = 0.4, label=\"Daily Exits\") # ranked by Exits and showing exits\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "# rects1 = ax.bar(x - width/2, men_means, width, label='Men')\n",
    "# rects2 = ax.bar(x + width/2, women_means, width, label='Women')\n",
    "\n",
    "rects1 = ax.bar(x - width/2, men_means, width, label='Men')\n",
    "rects2 = ax.bar(x + width/2, women_means, width, label='Women')\n",
    "\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('# of Entries/Exits')\n",
    "ax.set_title('Top 10 stations by total entries and exits')\n",
    "# ax.set_xticks(x)\n",
    "# ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "# ax.bar_label(rects1, padding=3)\n",
    "# ax.bar_label(rects2, padding=3)\n",
    "\n",
    "\n",
    "# plt.legend(loc=\"upper right\")\n",
    "plt.xlabel('Station Name')\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "# plt.savefig('top_10.png')\n",
    "\n",
    "\n",
    "# # side by side? while maintaining same stations?\n",
    "\n",
    "# plt.bar(x=penn_day['DAY_OF_WEEK_NUM'] - 0.2,\n",
    "#         height=penn_day['DAILY_ENTRIES'], width = 0.4, label=\"Total Entries\")\n",
    "# plt.bar(x=penn_day['DAY_OF_WEEK_NUM'] + 0.2,\n",
    "#         height=penn_day['DAILY_EXITS'], width = 0.4, label=\"Total Exits\")\n",
    "# plt.legend(loc='upper left')\n",
    "# plt.xlabel('Day of the week')\n",
    "# plt.ylabel('Number of turnstile entries/exits (in millions)')\n",
    "# plt.xticks(np.arange(7),['Mo','Tu','We','Th','Fr','St','Sn']) # changing x-tick labels np.arange(7) is the index location of the labels, then list for actual labels that we want for the tick mark.\n",
    "# plt.title('Ridership by Day of the Week for 34 ST-PENN STA')\n",
    "# plt.savefig('penn_week_plot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75210b3",
   "metadata": {},
   "source": [
    "## Plot daily entries and exits for Penn Station (busiest by exits and entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debe52f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "penn_daily = station_daily[station_daily[\"STATION\"] == \"34 ST-PENN STA\"].copy() # copy not necessary because, it’s not manipulating the original df\n",
    "penn_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3025baf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(penn_daily['DATE'], penn_daily['DAILY_ENTRIES'], label=\"Daily Entries\")\n",
    "plt.plot(penn_daily['DATE'], penn_daily['DAILY_EXITS'], label=\"Daily Exits\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.ylabel('# of Entries/Exits')\n",
    "plt.xlabel('Date')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Daily Entries and Exits for 34 ST-PENN Station')\n",
    "\n",
    "\n",
    "# ???? Thanksgiving and Christmas makes sense... What's with the rest?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a95323",
   "metadata": {},
   "source": [
    "??? \n",
    "\n",
    "Public holidays celebrated in NY include:\n",
    "\n",
    "Labor Day Mon, Sep 7, 2020\n",
    "Columbus Day Mon, Oct 12, 2020\n",
    "Veterans Day Wed, Nov 11, 2020\n",
    "Thanksgiving Thu, Nov 26, 2020\n",
    "Christmas Day Fri, Dec 25, 2020\n",
    "New Year's Day Fri, Jan 1, 2021\n",
    "Martin Luther King Jr. Day Mon, Jan 18, 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ab45f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(penn_daily.sort_values(\"DAILY_ENTRIES\", ascending=False).head(15))\n",
    "print(penn_daily.sort_values(\"DAILY_ENTRIES\", ascending=False).tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eec2c35",
   "metadata": {},
   "source": [
    "## Weekly Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fe7640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dea36fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "penn_daily['DAY_OF_WEEK_NUM'] = pd.to_datetime(penn_daily['DATE']).dt.dayofweek\n",
    "# taking the 'DATE' converting into datetime object via 'to_datetime'; then extracting the day of the week using dt.dayofweek; dt. is an attribute within datetime object. .dayofweek, given dt gives day of the week. dt <-- what you use if you do anything with dates; helps you extract the datetime attribute of the series. dt; this is all pandas.\n",
    "penn_daily['WEEK_OF_YEAR'] = pd.to_datetime(penn_daily['DATE']).dt.week\n",
    "# .week <-- gives week of the year\n",
    "penn_daily.head() # 6 is Sunday 0 is Monday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bbda21",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, group in penn_daily.groupby('WEEK_OF_YEAR'):\n",
    "    plt.plot(group['DAY_OF_WEEK_NUM'], group['DAILY_ENTRIES'])\n",
    "# just a for loop; grouping of the Week of the year, for every week it is; and for each group plotting, with day of week as x-axis and daily entries as y axis.\n",
    "    \n",
    "    \n",
    "plt.xlabel('Day of the week')\n",
    "plt.ylabel('Number of turnstile entries')\n",
    "plt.xticks(np.arange(7),['Mo','Tu','We','Th','Fr','St','Sn']) # changing x-tick labels np.arange(7) is the index location of the labels, then list for actual labels that we want for the tick mark.\n",
    "plt.title('Ridership per day for 34 ST-PENN STA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a3628f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this one no good, see cell below\n",
    "\n",
    "# for i, group in penn_daily.groupby('WEEK_OF_YEAR'):\n",
    "#     plt.plot(group['DAY_OF_WEEK_NUM'], group['DAILY_ENTRIES'])\n",
    "# # just a for loop; grouping of the Week of the year, for every week it is; and for each group plotting, with day of week as x-axis and daily entries as y axis.\n",
    "\n",
    "penn_daily.groupby('DAY_OF_WEEK_NUM').sum('TOTAL_ENTRIES').plot.bar(rot=15, title=\"Ridership by Day of Week for 34 ST-PENN STA\");\n",
    "plt.show(block=True);\n",
    "\n",
    "plt.xlabel('Day of the week')\n",
    "plt.ylabel('Number of turnstile entries')\n",
    "plt.xticks(np.arange(7),['Mo','Tu','We','Th','Fr','St','Sn']) # changing x-tick labels np.arange(7) is the index location of the labels, then list for actual labels that we want for the tick mark.\n",
    "plt.title('Ridership per day for 34 ST-PENN STA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8622b8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca530303",
   "metadata": {},
   "outputs": [],
   "source": [
    "penn_day = penn_daily.groupby('DAY_OF_WEEK_NUM').sum('TOTAL_ENTRIES').reset_index()\n",
    "# plt.bar(X_axis - 0.2, Ygirls, 0.4, label = 'Girls')\n",
    "# plt.bar(X_axis + 0.2, Zboys, 0.4, label = 'Boys')\n",
    "plt.bar(x=penn_day['DAY_OF_WEEK_NUM'] - 0.2,\n",
    "        height=penn_day['DAILY_ENTRIES'], width = 0.4, label=\"Total Entries\")\n",
    "plt.bar(x=penn_day['DAY_OF_WEEK_NUM'] + 0.2,\n",
    "        height=penn_day['DAILY_EXITS'], width = 0.4, label=\"Total Exits\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Day of the week')\n",
    "plt.ylabel('Number of turnstile entries/exits (in millions)')\n",
    "plt.xticks(np.arange(7),['Mo','Tu','We','Th','Fr','St','Sn']) # changing x-tick labels np.arange(7) is the index location of the labels, then list for actual labels that we want for the tick mark.\n",
    "plt.title('Ridership by Day of the Week for 34 ST-PENN STA')\n",
    "plt.savefig('penn_week_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e146d2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "penn_day = penn_daily.groupby('DAY_OF_WEEK_NUM').sum('TOTAL_ENTRIES').reset_index()\n",
    "# plt.bar(x=penn_day['DAY_OF_WEEK_NUM'],\n",
    "#         height=penn_day['DAILY_ENTRIES'], label=\"Total Entries\")\n",
    "# plt.bar(x=penn_day['DAY_OF_WEEK_NUM'],\n",
    "#         height=penn_day['DAILY_EXITS'], label=\"Total Exits\")\n",
    "# plt.xlabel('Day of the week')\n",
    "# plt.ylabel('Number of turnstile entries/exits')\n",
    "# plt.xticks(np.arange(7),['Mo','Tu','We','Th','Fr','St','Sn']) # changing x-tick labels np.arange(7) is the index location of the labels, then list for actual labels that we want for the tick mark.\n",
    "# plt.title('Ridership by Day of the Week for 34 ST-PENN STA')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "# entries_bar = ax.bar(x=penn_day['DAY_OF_WEEK_NUM'],\n",
    "#         height=penn_day['DAILY_ENTRIES'], label=\"Total Entries\")\n",
    "# exits_bar = ax.bar(x=penn_day['DAY_OF_WEEK_NUM'],\n",
    "#         height=penn_day['DAILY_EXITS'], label=\"Total Exits\")\n",
    "\n",
    "ax.bar(x=penn_day['DAY_OF_WEEK_NUM'],\n",
    "        height=penn_day['DAILY_ENTRIES'], width, label=\"Total Entries\")\n",
    "ax.bar(x=penn_day['DAY_OF_WEEK_NUM'],\n",
    "        height=penn_day['DAILY_EXITS'], width, label=\"Total Exits\")\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_xlabel('Day of the week')\n",
    "ax.set_ylabel('Number of turnstile entries/exits')\n",
    "ax.set_title('Ridership by Day of the Week for 34 ST-PENN STA')\n",
    "ax.set_xticks(np.arange(7))\n",
    "ax.set_xticklabels(['Mo','Tu','We','Th','Fr','St','Sn'])\n",
    "ax.legend()\n",
    "\n",
    "# ax.bar_label(entries_bar, padding=3)\n",
    "# ax.bar_label(entries_bar, padding=3)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0f48ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['G1', 'G2', 'G3', 'G4', 'G5']\n",
    "men_means = [20, 34, 30, 35, 27]\n",
    "women_means = [25, 32, 34, 20, 25]\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, men_means, width, label='Men')\n",
    "rects2 = ax.bar(x + width/2, women_means, width, label='Women')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Scores by group and gender')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "# ax.bar_label(rects1, padding=3)\n",
    "# ax.bar_label(rects2, padding=3)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f4da8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
